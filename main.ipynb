{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamini\n",
    "import logging\n",
    "import random\n",
    "from typing import AsyncIterator, Iterator, Union\n",
    "import sqlite3\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "from lamini.generation.base_prompt_object import PromptObject\n",
    "from lamini.generation.generation_node import GenerationNode\n",
    "from lamini.generation.base_prompt_object import PromptObject\n",
    "from lamini.generation.generation_pipeline import GenerationPipeline\n",
    "from util.get_schema import get_schema, get_schema_s\n",
    "from util.make_llama_3_prompt import make_llama_3_prompt\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "engine = sqlite3.connect(\"./nba_roster.db\")\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self,\n",
    "                 max_examples=100,\n",
    "                 sql_model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "                 gold_file_name=\"gold-test-set.jsonl\",\n",
    "                 training_file_name=\"generated_queries.jsonl\",\n",
    "                 num_to_generate=10):\n",
    "        self.sql_model_name = sql_model_name\n",
    "        self.max_examples = max_examples\n",
    "        self.gold_file_name = gold_file_name\n",
    "        self.training_file_name = training_file_name\n",
    "        self.num_to_generate = num_to_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are an NBA analyst with 15 years of experience writing complex SQL queries.\\n\"\n",
    "system += (\n",
    "    \"Consider a table called 'nba_roster' with the following schema (columns)\\n\"\n",
    ")\n",
    "system += get_schema_s()\n",
    "system += \"Consider the following questions, and queries used to answer them:\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an NBA analyst with 15 years of experience writing complex SQL queries.\\nConsider a table called \\'nba_roster\\' with the following schema (columns)\\n0|Team|TEXT eg. \"Toronto Raptors\"\\n1|NAME|TEXT eg. \"Otto Porter Jr.\"\\n2|Jersey|TEXT eg. \"0\" and when null has a value \"NA\"\\n3|POS|TEXT eg. \"PF\"\\n4|AGE|INT eg. \"22\" in years\\n5|HT|TEXT eg. `6\\' 7\"` or `6\\' 10\"` castable to int\\n6|WT|TEXT eg. \"232 lbs\" \\n7|COLLEGE|TEXT eg. \"Michigan\" and when null has a value \"--\"\\n8|SALARY|TEXT eg. \"$9,945,830\" and when null has a value \"--\"\\nConsider the following questions, and queries used to answer them:\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"What is the median weight in the NBA?\"\"\"\n",
    "sql = \"select CAST(SUBSTR(WT, 1, INSTR(WT,' ')) as INTEGER) as percentile from nba_roster order by percentile limit 1 offset (select count(*) from nba_roster)/2;\"\n",
    "\n",
    "system += \"Question: \" + question + \"\\n\"\n",
    "system += \"Query: \" + sql + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an NBA analyst with 15 years of experience writing complex SQL queries.\n",
      "Consider a table called 'nba_roster' with the following schema (columns)\n",
      "0|Team|TEXT eg. \"Toronto Raptors\"\n",
      "1|NAME|TEXT eg. \"Otto Porter Jr.\"\n",
      "2|Jersey|TEXT eg. \"0\" and when null has a value \"NA\"\n",
      "3|POS|TEXT eg. \"PF\"\n",
      "4|AGE|INT eg. \"22\" in years\n",
      "5|HT|TEXT eg. `6' 7\"` or `6' 10\"` castable to int\n",
      "6|WT|TEXT eg. \"232 lbs\" \n",
      "7|COLLEGE|TEXT eg. \"Michigan\" and when null has a value \"--\"\n",
      "8|SALARY|TEXT eg. \"$9,945,830\" and when null has a value \"--\"\n",
      "Consider the following questions, and queries used to answer them:\n",
      "Question: What is the median weight in the NBA?\n",
      "Query: select CAST(SUBSTR(WT, 1, INSTR(WT,' ')) as INTEGER) as percentile from nba_roster order by percentile limit 1 offset (select count(*) from nba_roster)/2;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Write two queries that are similar but different to those above.\\n\"\n",
    "user += \"Format the queries as a JSON object, i.e.\\n\"\n",
    "user += '{ \"explanation\": str, \"sql_query_1\" : str, \"sql_query_2\": str }.\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write two queries that are similar but different to those above.\n",
      "Format the queries as a JSON object, i.e.\n",
      "{ \"explanation\": str, \"sql_query_1\" : str, \"sql_query_2\": str }.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user += \"First write an explanation of why you decided to write these new queries in about 3-5 sentences, then write valid sqlite SQL queries for each of the 2 new queries. Make sure each query is complete and ends with a ;\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write two queries that are similar but different to those above.\n",
      "Format the queries as a JSON object, i.e.\n",
      "{ \"explanation\": str, \"sql_query_1\" : str, \"sql_query_2\": str }.\n",
      "First write an explanation of why you decided to write these new queries in about 3-5 sentences, then write valid sqlite SQL queries for each of the 2 new queries. Make sure each query is complete and ends with a ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = make_llama_3_prompt(user, system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'explanation': 'I decided to write these new queries to provide more insights into the NBA data. The first query calculates the average height of players in the NBA, while the second query finds the team with the highest average salary. These queries are similar to the original query in that they involve extracting and manipulating', 'sql_query_1': \"SELECT AVG(CAST(SUBSTR(HT, 1, INSTR(HT,'')-1) AS INTEGER)) AS average_height FROM nba_roster\", 'sql_query_2': \"SELECT Team, AVG(CAST(SUBSTR(SALARY, 2, LENGTH(SALARY)-2) AS INTEGER)) AS average_salary FROM nba_roster WHERE SALARY!= '--' GROUP BY Team ORDER BY average_salary DESC LIMIT 1\"}\n"
     ]
    }
   ],
   "source": [
    "llm = lamini.Lamini(model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "result = llm.generate(prompt, output_type={ \"explanation\": \"str\", \"sql_query_1\" : \"str\", \"sql_query_2\": \"str\" }, max_new_tokens=200)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sql_query(query):\n",
    "    try:\n",
    "        pd.read_sql(query, con=engine)\n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Error in SQL query: {e}\")\n",
    "        return False\n",
    "\n",
    "    logger.info(f\"SQL query {query} is valid\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sql_query(result[\"sql_query_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_sql_query(result[\"sql_query_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap it all up together in a class\n",
    "\n",
    "class ModelStage(GenerationNode):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "            max_new_tokens=300,\n",
    "        )\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt: Union[Iterator[PromptObject], AsyncIterator[PromptObject]],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        prompt = self.add_template(prompt)\n",
    "\n",
    "        results = super().generate(\n",
    "            prompt,\n",
    "            output_type={\n",
    "                \"explanation\": \"str\",\n",
    "                \"sql_query_1\": \"str\",\n",
    "                \"sql_query_2\": \"str\",\n",
    "            },\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "    async def add_template(self, prompts):\n",
    "        async for prompt in prompts:\n",
    "            new_prompt = make_llama_3_prompt(**self.make_prompt(prompt.data))\n",
    "            yield PromptObject(prompt=new_prompt, data=prompt.data)\n",
    "\n",
    "    async def process_results(self, results):\n",
    "        async for result in results:\n",
    "            if result is None:\n",
    "                continue\n",
    "\n",
    "            if result.response is None:\n",
    "                continue\n",
    "\n",
    "            logger.info(\"=====================================\")\n",
    "            logger.info(f\"Generated query 1: {result.response['sql_query_1']}\")\n",
    "            logger.info(f\"Generated query 2: {result.response['sql_query_2']}\")\n",
    "            logger.info(\"=====================================\")\n",
    "\n",
    "            if self.check_sql_query(result.response[\"sql_query_1\"]):\n",
    "                new_result = PromptObject(prompt=\"\", data=copy.deepcopy(result.data))\n",
    "                new_result.data.generated_sql_query = result.response[\"sql_query_1\"]\n",
    "                yield new_result\n",
    "\n",
    "            if self.check_sql_query(result.response[\"sql_query_2\"]):\n",
    "                new_result = PromptObject(prompt=\"\", data=copy.deepcopy(result.data))\n",
    "                new_result.data.generated_sql_query = result.response[\"sql_query_2\"]\n",
    "                yield new_result\n",
    "\n",
    "    def make_prompt(self, data):\n",
    "        system = \"You are an NBA analyst with 15 years of experience writing complex SQL queries.\\n\"\n",
    "        system += (\n",
    "            \"Consider a table called 'nba_roster' with the following schema (columns)\\n\"\n",
    "        )\n",
    "        system += get_schema()\n",
    "        system += \"Consider the following questions, and queries used to answer them:\\n\"\n",
    "        for example in data.sample:\n",
    "            system += \"Question: \" + example[\"question\"] + \"\\n\"\n",
    "            system += \"Query: \" + example[\"sql\"] + \"\\n\"\n",
    "\n",
    "        # Important: generate relevant queries to your reference data\n",
    "        # Ideally, close to those that are failing so you can show the model examples of how to do it right!\n",
    "        user = \"Write two queries that are similar but different to those above.\\n\"\n",
    "        user += \"Format the queries as a JSON object, i.e.\\n\"\n",
    "        user += '{ \"explanation\": str, \"sql_query_1\" : str, \"sql_query_2\": str }.\\n'\n",
    "\n",
    "        # Next, use Chain of Thought (CoT) and prompt-engineering to help with generating SQL queries\n",
    "        user += \"First write an explanation of why you decided to write these new queries in about 3-5 sentences, then write valid sqlite SQL queries for each of the 2 new queries. Make sure each query is complete and ends with a ;\\n\"\n",
    "\n",
    "        return {\"system\": system, \"user\": user}\n",
    "\n",
    "    def check_sql_query(self, query):\n",
    "        try:\n",
    "            pd.read_sql(query, con=engine)\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error in SQL query: {e}\")\n",
    "            return False\n",
    "\n",
    "        logger.info(f\"SQL query {query} is valid\")\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are an NBA analyst with 15 years of experience writing complex SQL queries.\\n\"\n",
    "system += (\n",
    "    \"Consider a table called 'nba_roster' with the following schema (columns)\\n\"\n",
    ")\n",
    "system += get_schema() + \"\\n\"\n",
    "system += \"Queries, and questions that they are used to answer:\\n\"\n",
    "\n",
    "example_question = \"\"\"What is the median weight in the NBA?\"\"\"\n",
    "example_sql = \"select CAST(SUBSTR(WT, 1, INSTR(WT,' ')) as INTEGER) as percentile from nba_roster order by percentile limit 1 offset (select count(*) from nba_roster)/2;\"\n",
    "\n",
    "system += \"Question: \" + example_question + \"\\n\"\n",
    "system += \"Query: \" + example_sql + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql = result[\"sql_query_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Now consider the following query.\\n\"\n",
    "user += \"Query: \" + generated_sql + \"\\n\"\n",
    "user += \"Write a question that this query could be used to answer.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "user += \"Format your response as a JSON object, i.e.\\n\"\n",
    "user += '{ \"explanation\": str, \"question\": str }.\\n'\n",
    "\n",
    "user += \"First write an explanation in about 3-5 sentences, then write a one sentence question.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'explanation': 'This query calculates the average salary for each team in the NBA, excluding teams with unknown salaries. It does this by first removing the dollar sign and any leading or trailing characters from the salary string, then converting the remaining characters to an integer. The results are then grouped by team and ordered in descending order by average salary, with the team having the highest average salary returned first. The LIMIT 1 clause ensures that only the top team is returned', 'question': 'Which team has the highest average salary among all teams in the NBA'}\n"
     ]
    }
   ],
   "source": [
    "prompt = make_llama_3_prompt(user, system)\n",
    "result = llm.generate(prompt, output_type={ \"explanation\": \"str\", \"question\" : \"str\" }, max_new_tokens=200)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap it all up together in a class which generates a question\n",
    "# given a query\n",
    "\n",
    "class QuestionStage(GenerationNode):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "            max_new_tokens=150,\n",
    "        )\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt: Union[Iterator[PromptObject], AsyncIterator[PromptObject]],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        results = super().generate(\n",
    "            prompt,\n",
    "            output_type={\n",
    "                \"explanation\": \"str\",\n",
    "                \"question\": \"str\",\n",
    "            },\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def preprocess(self, obj: PromptObject):\n",
    "        new_prompt = make_llama_3_prompt(**self.make_question_prompt(obj.data))\n",
    "        obj.prompt = new_prompt\n",
    "\n",
    "    def make_question_prompt(self, data):\n",
    "        system = \"You are an NBA analyst with 15 years of experience writing complex SQL queries.\\n\"\n",
    "        system += (\n",
    "            \"Consider a table called 'nba_roster' with the following schema (columns)\\n\"\n",
    "        )\n",
    "        system += get_schema() + \"\\n\"\n",
    "        system += \"Queries, and questions that they are used to answer:\\n\"\n",
    "        for example in data.sample:\n",
    "            system += \"Query: \" + example[\"sql\"] + \"\\n\"\n",
    "            system += \"Question: \" + example[\"question\"] + \"\\n\"\n",
    "\n",
    "        user = \"Now consider the following query.\\n\"\n",
    "        user += \"Query: \" + data.generated_sql_query + \"\\n\"\n",
    "        user += \"Write a question that this query could be used to answer.\\n\"\n",
    "\n",
    "        # Using Chain of Thought (CoT) again\n",
    "        # This time you can do it programmatically with function calling, so you can easily extract a question out of the JSON object\n",
    "        user += \"Format your response as a JSON object, i.e.\\n\"\n",
    "        user += '{ \"explanation\": str, \"question\": str }.\\n'\n",
    "\n",
    "        user += \"First write an explanation in about 3-5 sentences, then write a one sentence question.\\n\"\n",
    "\n",
    "        return {\"system\": system, \"user\": user}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryGenPipeline(GenerationPipeline):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_stage = ModelStage()\n",
    "        self.question_stage = QuestionStage()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_stage(x)\n",
    "        x = self.question_stage(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_query_gen_pipeline(gold_queries):\n",
    "    return QueryGenPipeline().call(gold_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate N samples, for every example in the gold dataset\n",
    "\n",
    "all_examples = []\n",
    "\n",
    "async def load_gold_queries(args):\n",
    "    path = f\"data/{args.gold_file_name}\"\n",
    "\n",
    "    with jsonlines.open(path) as reader:\n",
    "        global all_examples\n",
    "\n",
    "        all_examples = [obj for obj in reader]\n",
    "\n",
    "    sample_count = args.num_to_generate\n",
    "    sample_size = 3\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    for i in range(sample_count):\n",
    "        example_sample = ExampleSample(random.sample(all_examples, sample_size), i)\n",
    "        yield PromptObject(prompt=\"\", data=example_sample)\n",
    "\n",
    "\n",
    "class ExampleSample:\n",
    "    def __init__(self, sample, index):\n",
    "        self.sample = sample\n",
    "        self.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save_generation_results(results, args):\n",
    "    path = f\"data/{args.training_file_name}\"\n",
    "\n",
    "    pbar = tqdm(desc=\"Saving results\", unit=\" results\")\n",
    "    with jsonlines.open(path, \"w\") as writer:\n",
    "\n",
    "        async for result in results:\n",
    "            writer.write(\n",
    "                {\n",
    "                    \"question\": result.response[\"question\"],\n",
    "                    \"sql\": result.data.generated_sql_query,\n",
    "                }\n",
    "            )\n",
    "            pbar.update()\n",
    "\n",
    "        for example in all_examples:\n",
    "            writer.write(example)\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "Exception",
     "evalue": "Must use Python 3.10 or greater for this feature",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m gold_queries \u001b[38;5;241m=\u001b[39m load_gold_queries(args)\n\u001b[1;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_query_gen_pipeline(gold_queries)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m save_generation_results(results, args)\n",
      "Cell \u001b[0;32mIn[43], line 7\u001b[0m, in \u001b[0;36msave_generation_results\u001b[0;34m(results, args)\u001b[0m\n\u001b[1;32m      4\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving results\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jsonlines\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m      8\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m      9\u001b[0m             {\n\u001b[1;32m     10\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgenerated_sql_query,\n\u001b[1;32m     12\u001b[0m             }\n\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_env/lib/python3.9/site-packages/lamini/generation/generation_pipeline.py:117\u001b[0m, in \u001b[0;36mGenerationPipeline.call\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    115\u001b[0m     prompt: AsyncIterator,\n\u001b[1;32m    116\u001b[0m ):\n\u001b[0;32m--> 117\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call(prompt)\n\u001b[1;32m    118\u001b[0m     finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m finished:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llm_env/lib/python3.9/site-packages/lamini/generation/generation_pipeline.py:50\u001b[0m, in \u001b[0;36mGenerationPipeline.__call\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreservation_api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_inference_queue\u001b[38;5;241m.\u001b[39mreservation_api\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust use Python 3.10 or greater for this feature\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m model_names \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     52\u001b[0m max_tokens \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mException\u001b[0m: Must use Python 3.10 or greater for this feature"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "gold_queries = load_gold_queries(args)\n",
    "results = await run_query_gen_pipeline(gold_queries)\n",
    "await save_generation_results(results, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
